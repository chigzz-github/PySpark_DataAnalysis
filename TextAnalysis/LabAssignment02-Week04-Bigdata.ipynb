{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "import sys\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "sparkConf = SparkConf().setAppName(\"Week04-BigData\")\n",
    "sparkContext = SparkContext(conf=sparkConf)\n",
    " \n",
    "data_df = sparkContext.textFile(\"C:/DataMngtBigData/Week04/README.md\").flatMap(lambda line: line.split(\" \"))\n",
    " \n",
    "ReadmeCount = data_df.map(lambda word: (word, 1)).reduceByKey(lambda a,b:a +b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReadmeCount.saveAsTextFile(\"ReadmeCounts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('#', 1)\n",
      "('Apache', 1)\n",
      "('Spark', 15)\n",
      "('', 72)\n",
      "('is', 7)\n",
      "('It', 2)\n",
      "('provides', 1)\n",
      "('high-level', 1)\n",
      "('APIs', 1)\n",
      "('in', 5)\n",
      "('Scala,', 1)\n",
      "('Java,', 1)\n",
      "('an', 4)\n",
      "('optimized', 1)\n",
      "('engine', 1)\n",
      "('supports', 2)\n",
      "('computation', 1)\n",
      "('analysis.', 1)\n",
      "('set', 2)\n",
      "('of', 5)\n",
      "('tools', 1)\n",
      "('SQL', 2)\n",
      "('MLlib', 1)\n",
      "('machine', 1)\n",
      "('learning,', 1)\n",
      "('GraphX', 1)\n",
      "('graph', 1)\n",
      "('processing,', 1)\n",
      "('Documentation', 1)\n",
      "('latest', 1)\n",
      "('programming', 1)\n",
      "('guide,', 1)\n",
      "('[project', 1)\n",
      "('README', 1)\n",
      "('only', 1)\n",
      "('basic', 1)\n",
      "('instructions.', 1)\n",
      "('Building', 1)\n",
      "('using', 3)\n",
      "('[Apache', 1)\n",
      "('run:', 1)\n",
      "('do', 2)\n",
      "('this', 1)\n",
      "('downloaded', 1)\n",
      "('documentation', 3)\n",
      "('project', 1)\n",
      "('site,', 1)\n",
      "('at', 2)\n",
      "('Spark\"](http://spark.apache.org/docs/latest/building-spark.html).', 1)\n",
      "('development', 1)\n",
      "('tips,', 1)\n",
      "('developing', 1)\n",
      "('IDE,', 1)\n",
      "('[\"Useful', 1)\n",
      "('Developer', 1)\n",
      "('Tools\"](http://spark.apache.org/developer-tools.html).', 1)\n",
      "('Interactive', 2)\n",
      "('Shell', 2)\n",
      "('The', 1)\n",
      "('way', 1)\n",
      "('start', 1)\n",
      "('Try', 1)\n",
      "('following', 2)\n",
      "('1000:', 2)\n",
      "('scala>', 1)\n",
      "('1000).count()', 1)\n",
      "('Python', 2)\n",
      "('Alternatively,', 1)\n",
      "('use', 3)\n",
      "('And', 1)\n",
      "('run', 7)\n",
      "('Example', 1)\n",
      "('several', 1)\n",
      "('programs', 2)\n",
      "('them,', 1)\n",
      "('`./bin/run-example', 1)\n",
      "('[params]`.', 1)\n",
      "('example:', 1)\n",
      "('./bin/run-example', 2)\n",
      "('SparkPi', 2)\n",
      "('variable', 1)\n",
      "('when', 1)\n",
      "('examples', 2)\n",
      "('spark://', 1)\n",
      "('URL,', 1)\n",
      "('YARN,', 1)\n",
      "('\"local\"', 1)\n",
      "('locally', 2)\n",
      "('N', 1)\n",
      "('abbreviated', 1)\n",
      "('class', 2)\n",
      "('name', 1)\n",
      "('package.', 1)\n",
      "('instance:', 1)\n",
      "('print', 1)\n",
      "('usage', 1)\n",
      "('help', 1)\n",
      "('no', 1)\n",
      "('params', 1)\n",
      "('are', 1)\n",
      "('Testing', 1)\n",
      "('Spark](#building-spark).', 1)\n",
      "('Once', 1)\n",
      "('built,', 1)\n",
      "('tests', 2)\n",
      "('using:', 1)\n",
      "('./dev/run-tests', 1)\n",
      "('Please', 4)\n",
      "('guidance', 2)\n",
      "('module,', 1)\n",
      "('individual', 1)\n",
      "('integration', 1)\n",
      "('test,', 1)\n",
      "('Note', 1)\n",
      "('About', 1)\n",
      "('uses', 1)\n",
      "('library', 1)\n",
      "('HDFS', 1)\n",
      "('other', 1)\n",
      "('Hadoop-supported', 1)\n",
      "('storage', 1)\n",
      "('systems.', 1)\n",
      "('Because', 1)\n",
      "('have', 1)\n",
      "('changed', 1)\n",
      "('different', 1)\n",
      "('versions', 1)\n",
      "('Hadoop,', 2)\n",
      "('must', 1)\n",
      "('against', 1)\n",
      "('version', 1)\n",
      "('refer', 2)\n",
      "('particular', 2)\n",
      "('distribution', 1)\n",
      "('Hive', 2)\n",
      "('Thriftserver', 1)\n",
      "('distributions.', 1)\n",
      "('[Configuration', 1)\n",
      "('Guide](http://spark.apache.org/docs/latest/configuration.html)', 1)\n",
      "('online', 1)\n",
      "('overview', 1)\n",
      "('configure', 1)\n",
      "('Spark.', 1)\n",
      "('Contributing', 1)\n",
      "('started', 1)\n",
      "('contributing', 1)\n",
      "('project.', 1)\n",
      "('a', 9)\n",
      "('fast', 1)\n",
      "('and', 10)\n",
      "('general', 3)\n",
      "('cluster', 2)\n",
      "('computing', 1)\n",
      "('system', 1)\n",
      "('for', 12)\n",
      "('Big', 1)\n",
      "('Data.', 1)\n",
      "('Python,', 2)\n",
      "('R,', 1)\n",
      "('that', 2)\n",
      "('graphs', 1)\n",
      "('data', 1)\n",
      "('also', 5)\n",
      "('rich', 1)\n",
      "('higher-level', 1)\n",
      "('including', 4)\n",
      "('DataFrames,', 1)\n",
      "('Streaming', 1)\n",
      "('stream', 1)\n",
      "('processing.', 1)\n",
      "('<http://spark.apache.org/>', 1)\n",
      "('##', 9)\n",
      "('Online', 1)\n",
      "('You', 3)\n",
      "('can', 6)\n",
      "('find', 1)\n",
      "('the', 23)\n",
      "('documentation,', 1)\n",
      "('on', 7)\n",
      "('web', 1)\n",
      "('page](http://spark.apache.org/documentation.html).', 1)\n",
      "('This', 2)\n",
      "('file', 1)\n",
      "('contains', 1)\n",
      "('setup', 1)\n",
      "('built', 1)\n",
      "('Maven](http://maven.apache.org/).', 1)\n",
      "('To', 2)\n",
      "('build', 3)\n",
      "('its', 1)\n",
      "('example', 3)\n",
      "('programs,', 1)\n",
      "('build/mvn', 1)\n",
      "('-DskipTests', 1)\n",
      "('clean', 1)\n",
      "('package', 1)\n",
      "('(You', 1)\n",
      "('not', 1)\n",
      "('need', 1)\n",
      "('to', 17)\n",
      "('if', 4)\n",
      "('you', 4)\n",
      "('pre-built', 1)\n",
      "('package.)', 1)\n",
      "('More', 1)\n",
      "('detailed', 2)\n",
      "('available', 1)\n",
      "('from', 1)\n",
      "('[\"Building', 1)\n",
      "('For', 3)\n",
      "('info', 1)\n",
      "('see', 3)\n",
      "('Scala', 2)\n",
      "('easiest', 1)\n",
      "('through', 1)\n",
      "('shell:', 2)\n",
      "('./bin/spark-shell', 1)\n",
      "('command,', 2)\n",
      "('which', 2)\n",
      "('should', 2)\n",
      "('return', 2)\n",
      "('sc.parallelize(1', 1)\n",
      "('prefer', 1)\n",
      "('./bin/pyspark', 1)\n",
      "('>>>', 1)\n",
      "('sc.parallelize(range(1000)).count()', 1)\n",
      "('Programs', 1)\n",
      "('comes', 1)\n",
      "('with', 3)\n",
      "('sample', 1)\n",
      "('`examples`', 2)\n",
      "('directory.', 1)\n",
      "('one', 2)\n",
      "('<class>', 1)\n",
      "('will', 1)\n",
      "('Pi', 1)\n",
      "('locally.', 1)\n",
      "('MASTER', 1)\n",
      "('environment', 1)\n",
      "('running', 1)\n",
      "('submit', 1)\n",
      "('cluster.', 1)\n",
      "('be', 2)\n",
      "('mesos://', 1)\n",
      "('or', 3)\n",
      "('\"yarn\"', 1)\n",
      "('thread,', 1)\n",
      "('\"local[N]\"', 1)\n",
      "('threads.', 1)\n",
      "('MASTER=spark://host:7077', 1)\n",
      "('Many', 1)\n",
      "('given.', 1)\n",
      "('Running', 1)\n",
      "('Tests', 1)\n",
      "('first', 1)\n",
      "('requires', 1)\n",
      "('[building', 1)\n",
      "('how', 3)\n",
      "('[run', 1)\n",
      "('tests](http://spark.apache.org/developer-tools.html#individual-tests).', 1)\n",
      "('There', 1)\n",
      "('Kubernetes', 1)\n",
      "('resource-managers/kubernetes/integration-tests/README.md', 1)\n",
      "('A', 1)\n",
      "('Hadoop', 3)\n",
      "('Versions', 1)\n",
      "('core', 1)\n",
      "('talk', 1)\n",
      "('protocols', 1)\n",
      "('same', 1)\n",
      "('your', 1)\n",
      "('runs.', 1)\n",
      "('[\"Specifying', 1)\n",
      "('Version', 1)\n",
      "('Enabling', 1)\n",
      "('YARN\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn)', 1)\n",
      "('building', 2)\n",
      "('Configuration', 1)\n",
      "('review', 1)\n",
      "('[Contribution', 1)\n",
      "('guide](http://spark.apache.org/contributing.html)', 1)\n",
      "('information', 1)\n",
      "('get', 1)\n"
     ]
    }
   ],
   "source": [
    "for words in ReadmeCount.collect():\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
